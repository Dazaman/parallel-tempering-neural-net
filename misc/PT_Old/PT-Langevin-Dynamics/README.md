# Parallel Tempering with SGD as weight updation

We use parallel tempering with backward propagation for weights using Stochastic Gradient Descent of the neural network for chaotic time series prediction in various benchmark datasets.

The code of the algorithm can be found in the `code` folder. The results may be found for some of the datasets in `results` folder.
